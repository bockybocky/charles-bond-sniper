import streamlit as st
import pandas as pd
from datetime import datetime
import io
import re

# --- 1. é é¢åŸºç¤è¨­å®š ---
st.set_page_config(
    page_title="Charles æˆ°æƒ…å®¤ V17.3 Smart", 
    page_icon="âš¡", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# ğŸ¨ æ ¸å¿ƒç¾åŒ–æ¨¡çµ„ (Dark Mode)
# ==========================================
def inject_custom_css():
    st.markdown("""
        <style>
        .stApp { background-color: #0E1117; color: #FAFAFA; font-family: 'Microsoft JhengHei', sans-serif; }
        [data-testid="stSidebar"] { background-color: #161B22; border-right: 1px solid #30363D; }
        h1 { background: linear-gradient(to right, #00E5FF, #2979FF); -webkit-background-clip: text; -webkit-text-fill-color: transparent; font-weight: 800 !important; font-size: 2.2rem !important; }
        div[data-testid="stMetricValue"] { font-size: 2rem; color: #00FFD1; font-weight: 700; text-shadow: 0 0 10px rgba(0, 255, 209, 0.3); }
        div[data-testid="stMetricLabel"] { color: #8B949E; }
        .stTabs [data-baseweb="tab"] { background-color: #21262D; color: #C9D1D9; border: 1px solid #30363D; }
        .stTabs [aria-selected="true"] { background-color: #1F6FEB !important; color: white !important; border: 1px solid #1F6FEB; }
        [data-testid="stDataFrame"] { border: 1px solid #30363D; }
        </style>
    """, unsafe_allow_html=True)

inject_custom_css()

# ==========================================
# ğŸ§  æ™ºèƒ½åµæ¸¬å¼•æ“ (Smart Detection Engine)
# ==========================================
def detect_columns(df):
    """
    ä¸ä¾è³´æ¬„ä½åç¨±ï¼Œç›´æ¥åˆ†æå…§å®¹ä¾†çŒœæ¸¬å“ªä¸€æ¬„æ˜¯ CUSIPï¼Œå“ªä¸€æ¬„æ˜¯ Issue Date
    """
    col_cusip = None
    col_issue = None
    
    # 1. åµæ¸¬ CUSIP (ç‰¹å¾µï¼š9ç¢¼ï¼Œè‹±æ•¸æ··åˆ)
    # æˆ‘å€‘è¨ˆç®—æ¯ä¸€æ¬„ç¬¦åˆ CUSIP æ ¼å¼çš„æ¯”ä¾‹
    max_cusip_match = 0
    for col in df.columns:
        # è½‰æˆå­—ä¸²ä¸¦å»é™¤ç©ºç™½
        sample = df[col].astype(str).str.strip()
        # è¨ˆç®—ç¬¦åˆ 9 ç¢¼ä¸”åŒ…å«æ•¸å­—çš„æ¯”ä¾‹
        matches = sample.str.match(r'^[A-Z0-9]{9}$', case=False).sum()
        ratio = matches / len(df)
        
        if ratio > 0.5 and ratio > max_cusip_match: # å‡è¨­è¶…é 50% çš„åˆ—ç¬¦åˆæ ¼å¼
            max_cusip_match = ratio
            col_cusip = col

    # 2. åµæ¸¬ Issue Date (ç‰¹å¾µï¼šæ—¥æœŸæ ¼å¼)
    max_date_match = 0
    for col in df.columns:
        if col == col_cusip: continue # è·³éå·²èªå®šç‚º CUSIP çš„æ¬„ä½
        
        # å˜—è©¦è½‰æ›æ—¥æœŸ
        try:
            sample = pd.to_datetime(df[col], errors='coerce')
            valid_dates = sample.notna().sum()
            ratio = valid_dates / len(df)
            
            if ratio > 0.5 and ratio > max_date_match:
                max_date_match = ratio
                col_issue = col
        except:
            continue
            
    return col_cusip, col_issue

def load_master_data_smart(file):
    """
    æ™ºèƒ½è®€å– Master Fileï¼Œè™•ç†ç„¡ Header æˆ–äº‚ Header çš„æƒ…æ³
    """
    try:
        # å…ˆå˜—è©¦ç”¨é è¨­è®€å– (å‡è¨­æœ‰ Header)
        file.seek(0)
        df = pd.read_csv(file)
        
        # æª¢æŸ¥æ˜¯å¦è®€å–å¤±æ•— (ä¾‹å¦‚ç¬¬ä¸€è¡Œå°±è¢«ç•¶æˆ Header åƒæ‰äº†æ•¸æ“š)
        # å¦‚æœæ¬„ä½åç¨±çœ‹èµ·ä¾†åƒ CUSIP (å¦‚ "958102AT2")ï¼Œä»£è¡¨å®ƒæ˜¯ç„¡ Header æª”
        is_headless = False
        for col in df.columns:
            if re.match(r'^[A-Z0-9]{9}$', str(col), re.IGNORECASE):
                is_headless = True
                break
        
        if is_headless:
            file.seek(0)
            df = pd.read_csv(file, header=None) # é‡æ–°è®€å–ï¼Œä¸è¨­ Header
            
        # å•Ÿå‹•æ™ºèƒ½åµæ¸¬
        c_cusip, c_issue = detect_columns(df)
        
        if c_cusip is not None and c_issue is not None:
            # æ¨™æº–åŒ–è¼¸å‡º
            df_clean = pd.DataFrame()
            df_clean['CUSIP'] = df[c_cusip].astype(str).str.strip()
            df_clean['Issue_Date_Clean'] = pd.to_datetime(df[c_issue], errors='coerce')
            return df_clean, f"âœ… æ™ºèƒ½åµæ¸¬æˆåŠŸ (CUSIPæ¬„: {c_cusip}, æ—¥æœŸæ¬„: {c_issue})"
        else:
            return None, "âŒ ç„¡æ³•è‡ªå‹•è­˜åˆ¥ CUSIP æˆ–æ—¥æœŸæ¬„ä½ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼ã€‚"
            
    except Exception as e:
        return None, f"è®€å–éŒ¯èª¤: {str(e)}"

# --- æ ¸å¿ƒå·¥å…· ---
def clean_currency(x):
    if isinstance(x, (int, float)): return x
    if pd.isna(x) or str(x).strip() in ['-', '']: return None
    clean_str = str(x).replace('$', '').replace(',', '').replace('"', '').strip()
    try: return float(clean_str)
    except: return None

def find_column(df, candidates):
    for col in df.columns:
        for cand in candidates:
            if cand.lower() == col.strip().lower():
                return col
    return None

def robust_parser(file):
    bytes_data = file.getvalue()
    text_data = None
    for enc in ['utf-8', 'cp1252', 'latin1']:
        try:
            text_data = bytes_data.decode(enc, errors='ignore')
            break
        except: continue
    if not text_data: return None, "ç„¡æ³•è§£ç¢¼æª”æ¡ˆ"
    
    lines = text_data.splitlines()
    header_idx = -1
    for i, line in enumerate(lines[:50]):
        if "Market Value" in line and ("Name" in line or "Issuer" in line):
            header_idx = i
            break
    if header_idx == -1: return None, "æ‰¾ä¸åˆ°æ¨™é¡Œåˆ—"
    
    try:
        clean_content = "\n".join(lines[header_idx:])
        df = pd.read_csv(io.StringIO(clean_content), quotechar='"')
        return df, None
    except Exception as e: return None, str(e)

# --- ä¸»ç¨‹å¼ ---
st.title("Charles æˆ°æƒ…å®¤ V17.3 Smart")
st.caption("VIC System // æ™ºèƒ½ç™¼è¡Œæ—¥å°æ¥")

with st.expander("ğŸ“˜ æ“ä½œæ‰‹å†Š (V17.3)", expanded=False):
    st.markdown("""
    * **å·¦å´ä¸Šå‚³ï¼š** iShares å®˜æ–¹ `ICVT_holdings.csv`
    * **å³å´ä¸Šå‚³ï¼š** æ‚¨çš„ `convertible_notes_issue_dates.csv` (æ”¯æ´ç„¡æ¨™é¡Œæ ¼å¼)
    * **ç³»çµ±åŠŸèƒ½ï¼š** è‡ªå‹•æŠ“å– CUSIP èˆ‡æ—¥æœŸï¼Œè¨ˆç®—ç™¼è¡Œå¹´ä»½ã€‚
    """)

# å´é‚Šæ¬„
with st.sidebar:
    st.markdown("### ğŸ›ï¸ æˆ°è¡“æ§åˆ¶å°")
    st.markdown("#### ğŸ’€ æ­»äº¡é–å®š")
    danger_price = st.slider("å±éšªåƒ¹æ ¼é–€æª»", 50.0, 100.0, 95.0, 1.0)
    ignore_coupon = st.checkbox("ç„¡è¦–ç¥¨é¢åˆ©ç‡", value=True)
    st.divider()
    st.markdown("#### ğŸš€ ç«ç®­é–å®š")
    rocket_price = st.slider("ç«ç®­åƒ¹æ ¼é–€æª»", 100.0, 200.0, 130.0, 5.0)

# ä¸Šå‚³å€
c1, c2 = st.columns(2)
with c1:
    uploaded_file = st.file_uploader("1. ä¸Šå‚³ ICVT å®˜æ–¹æª”", type=['csv'], label_visibility="visible", key="main")
with c2:
    uploaded_master = st.file_uploader("2. ä¸Šå‚³ç™¼è¡Œæ—¥æª” (Master)", type=['csv'], label_visibility="visible", key="master")

# é‚è¼¯è™•ç†
if uploaded_file is not None:
    df, error_msg = robust_parser(uploaded_file)
    
    if error_msg:
        st.error(f"âŒ å®˜æ–¹æª”æ¡ˆéŒ¯èª¤: {error_msg}")
    else:
        try:
            # 1. åŸºç¤æ¸…æ´—
            df.columns = df.columns.str.strip()
            col_name = find_column(df, ['Name', 'Issuer Name'])
            col_market = find_column(df, ['Market Value', 'Market Value ($)'])
            col_par = find_column(df, ['Par Value', 'Par'])
            col_maturity = find_column(df, ['Maturity', 'Maturity Date'])
            col_coupon = find_column(df, ['Coupon (%)', 'Coupon'])
            col_cusip = find_column(df, ['CUSIP', 'ISIN'])

            if not (col_name and col_market and col_par and col_maturity):
                st.error("âŒ å®˜æ–¹æª”æ¡ˆç¼ºå°‘é—œéµæ¬„ä½")
            else:
                df['Name_Clean'] = df[col_name]
                df['Market_Clean'] = df[col_market].apply(clean_currency)
                df['Par_Clean'] = df[col_par].apply(clean_currency)
                df['Maturity_Dt'] = pd.to_datetime(df[col_maturity], errors='coerce')
                df['Coupon_Clean'] = df[col_coupon].apply(clean_currency) if col_coupon else 0.0

                # 2. æ™ºèƒ½èåˆ Master Data
                df['Issue_Year'] = None
                if uploaded_master is not None:
                    df_master_clean, msg = load_master_data_smart(uploaded_master)
                    if df_master_clean is not None:
                        st.success(msg)
                        # Merge
                        if col_cusip:
                            df[col_cusip] = df[col_cusip].astype(str).str.strip()
                            df = df.merge(df_master_clean, left_on=col_cusip, right_on='CUSIP', how='left')
                            df['Issue_Year'] = df['Issue_Date_Clean'].dt.year
                            
                            # é¡¯ç¤ºå°æ¥ç‹€æ³
                            matched_count = df['Issue_Year'].notna().sum()
                            st.info(f"ğŸ”— å·²æˆåŠŸå°æ¥ {matched_count} ç­†ç™¼è¡Œå¹´ä»½æ•¸æ“š")
                    else:
                        st.warning(msg)

                # 3. ç¯©é¸èˆ‡é¡¯ç¤º
                df_valid = df.dropna(subset=['Market_Clean', 'Par_Clean', 'Maturity_Dt']).copy()
                df_valid['Bond_Price'] = (df_valid['Market_Clean'] / df_valid['Par_Clean']) * 100
                df_valid['Ticker_Search'] = "https://www.google.com/search?q=" + df_valid['Name_Clean'].str.replace(' ', '+') + "+stock+ticker"
                
                # æ™‚é–“éæ¿¾ 2026-2027
                mask_date = (df_valid['Maturity_Dt'] >= datetime(2026, 1, 1)) & \
                            (df_valid['Maturity_Dt'] <= datetime(2027, 12, 31))
                df_time = df_valid[mask_date].copy()

                if len(df_time) > 0:
                    if ignore_coupon:
                        danger = df_time[df_time['Bond_Price'] < danger_price]
                    else:
                        danger = df_time[(df_time['Bond_Price'] < danger_price) & (df_time['Coupon_Clean'] < 2.0)]
                    rocket = df_time[df_time['Bond_Price'] > rocket_price]
                    
                    # æ’åº
                    danger = danger.sort_values(by='Maturity_Dt')
                    rocket = rocket.sort_values(by='Maturity_Dt')
                    df_all = df_time.sort_values(by='Maturity_Dt')

                    # å„€è¡¨æ¿
                    st.markdown("---")
                    c1_m, c2_m, c3_m = st.columns(3)
                    c1_m.metric("ğŸ“Š æˆ°è¡“é›·é”", f"{len(df_time)}", "2026-27 ç›®æ¨™")
                    c2_m.metric("ğŸ’€ æ­»äº¡åå–®", f"{len(danger)}", f"ä½”æ¯” {len(danger)/len(df_time):.1%}")
                    c3_m.metric("ğŸš€ ç«ç®­åå–®", f"{len(rocket)}", f"ä½”æ¯” {len(rocket)/len(df_time):.1%}")
                    st.markdown("---")

                    t1, t2, t3 = st.tabs(["ğŸ’€ æ­»äº¡åå–®", "ğŸš€ ç«ç®­åå–®", "ğŸ“‹ å®Œæ•´æˆ°å ±"])
                    
                    cfg = {
                        "Name_Clean": st.column_config.TextColumn("å…¬å¸åç¨±", width="large"),
                        "Ticker_Search": st.column_config.LinkColumn("è³‡è¨Š", display_text="ğŸ”", width="small"),
                        "Maturity_Dt": st.column_config.DateColumn("åˆ°æœŸæ—¥", format="YYYY-MM-DD"),
                        "Issue_Year": st.column_config.NumberColumn("ç™¼è¡Œå¹´", format="%d"),
                        "Bond_Price": st.column_config.ProgressColumn("åƒ¹æ ¼å¼·åº¦", format="$%.2f", min_value=0, max_value=200),
                        "Coupon_Clean": st.column_config.NumberColumn("ç¥¨é¢åˆ©ç‡", format="%.2f%%"),
                        "Par_Clean": st.column_config.NumberColumn("ç¥¨é¢ç¸½é¡", format="$%d"),
                        "Market_Clean": st.column_config.NumberColumn("æŒæœ‰å¸‚å€¼", format="$%d")
                    }
                    cols = ['Name_Clean', 'Ticker_Search', 'Maturity_Dt', 'Issue_Year', 'Coupon_Clean', 'Bond_Price', 'Par_Clean']

                    with t1: st.dataframe(danger[cols], column_config=cfg, hide_index=True, use_container_width=True)
                    with t2: st.dataframe(rocket[cols], column_config=cfg, hide_index=True, use_container_width=True)
                    with t3: st.dataframe(df_all[cols], column_config=cfg, hide_index=True, use_container_width=True)
                else:
                    st.warning("âš ï¸ æ­¤å€é–“ç„¡ç›®æ¨™ã€‚")

        except Exception as e:
            st.error(f"âŒ ç³»çµ±éŒ¯èª¤: {e}")
